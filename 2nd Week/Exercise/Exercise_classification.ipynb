{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "colab": {
   "name": "Lec3_student_file_v1.ipynb",
   "provenance": [],
   "collapsed_sections": []
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "jggpB0qX0kJ9"
   },
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import numpy.random as rnd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Ignore useless warnings (see SciPy issue #5998)\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")\n",
    "\n",
    "def plot_generated_data(X, y):\n",
    "    plt.plot(X, y, \"b.\")\n",
    "    plt.xlabel(\"$x_1$\", fontsize=18)\n",
    "    plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
    "    plt.show()\n",
    "    \n",
    "def plot_gradient_descent(theta, eta, theta_path=None):\n",
    "    X_new = np.array([[0], [2]])\n",
    "    X_new_b = np.c_[np.ones((2, 1)), X_new]  # add x0 = 1 to each instance\n",
    "    m = len(X_b)\n",
    "    plt.plot(X, y, \"b.\")\n",
    "    n_iterations = 1000\n",
    "    for iteration in range(n_iterations):\n",
    "        if iteration < 10:\n",
    "            y_predict = X_new_b.dot(theta)\n",
    "            style = \"b-\" if iteration > 0 else \"r--\"\n",
    "            plt.plot(X_new, y_predict, style)\n",
    "        gradients = 2/m * X_b.T.dot(X_b.dot(theta) - y)\n",
    "        theta = theta - eta * gradients\n",
    "        if theta_path is not None:\n",
    "            theta_path.append(theta)\n",
    "    plt.xlabel(\"$x_1$\", fontsize=18)\n",
    "    plt.axis([0, 2, 0, 15])\n",
    "    plt.title(r\"$\\eta = {}$\".format(eta), fontsize=16)\n",
    "    \n",
    "def plot_stochastic_gradient_descent(X, y):\n",
    "    X_b = np.c_[np.ones((100, 1)), X]  # add x0 = 1 to each instance\n",
    "    X_new = np.array([[0], [2]])\n",
    "    X_new_b = np.c_[np.ones((2, 1)), X_new]  # add x0 = 1 to each instance\n",
    "\n",
    "    m = len(X_b)\n",
    "    n_epochs = 50\n",
    "    \n",
    "    theta = np.random.randn(2,1)  # random initialization\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for i in range(m):\n",
    "            if epoch == 0 and i < 20:                    # not shown in the book\n",
    "                y_predict = X_new_b.dot(theta)           # not shown\n",
    "                style = \"b-\" if i > 0 else \"r--\"         # not shown\n",
    "                plt.plot(X_new, y_predict, style)        # not shown\n",
    "            random_index = np.random.randint(m)\n",
    "            xi = X_b[random_index:random_index+1]\n",
    "            yi = y[random_index:random_index+1]\n",
    "            gradients = 2 * xi.T.dot(xi.dot(theta) - yi)\n",
    "            eta = learning_schedule(epoch * m + i)\n",
    "            theta = theta - eta * gradients\n",
    "\n",
    "    plt.plot(X, y, \"b.\")                                 # not shown\n",
    "    plt.xlabel(\"$x_1$\", fontsize=18)                     # not shown\n",
    "    plt.ylabel(\"$y$\", rotation=0, fontsize=18)           # not shown\n",
    "    plt.axis([0, 2, 0, 15])                              # not shown\n",
    "    plt.show()                                           # not shown\n",
    "    \n",
    "    \n",
    "def plot_logistic(_new, y_proba):\n",
    "    decision_boundary = X_new[y_proba[:, 1] >= 0.5][0]\n",
    "\n",
    "    plt.figure(figsize=(8, 3))\n",
    "    plt.plot(X[y==0], y[y==0], \"bs\")\n",
    "    plt.plot(X[y==1], y[y==1], \"g^\")\n",
    "    plt.plot([decision_boundary, decision_boundary], [-1, 2], \"k:\", linewidth=2)\n",
    "    plt.plot(X_new, y_proba[:, 1], \"g-\", linewidth=2, label=\"Iris virginica\")\n",
    "    plt.plot(X_new, y_proba[:, 0], \"b--\", linewidth=2, label=\"Not Iris virginica\")\n",
    "    plt.text(decision_boundary+0.02, 0.15, \"Decision  boundary\", fontsize=14, color=\"k\", ha=\"center\")\n",
    "    plt.arrow(decision_boundary, 0.08, -0.3, 0, head_width=0.05, head_length=0.1, fc='b', ec='b')\n",
    "    plt.arrow(decision_boundary, 0.92, 0.3, 0, head_width=0.05, head_length=0.1, fc='g', ec='g')\n",
    "    plt.xlabel(\"Petal width (cm)\", fontsize=14)\n",
    "    plt.ylabel(\"Probability\", fontsize=14)\n",
    "    plt.legend(loc=\"center left\", fontsize=14)\n",
    "    plt.axis([0, 3, -0.02, 1.02])\n",
    "    plt.show()"
   ],
   "execution_count": 482,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AOumH1he0kKB"
   },
   "source": [
    "# Ïó∞ÏäµÎ¨∏Ï†ú\n",
    "\n",
    "## Î¨∏Ï†ú 1,2 Îç∞Ïù¥ÌÑ∞ Ï§ÄÎπÑÏÇ¨Ìï≠\n",
    "* np.random.seed(42)\n",
    "* X = 5 * np.random.rand(100,1)\n",
    "* y = 20 + 9 * X + np.random.rand(100,1) * 3\n",
    "* X_b = np.c_[np.ones((100,1),X]\n",
    "* theta = np.random.randn(2,1)\n",
    "\n",
    "## Question 1\n",
    "Build a batch gradient descent with number of iterations = 100. What is the theta value if learning rate(e.g., eta) is set to 0.1 and 0.01?\n",
    "* Ans ;\n",
    " * eta = 0.1, theta = [[21.45978618], [ 9.00541536]]\n",
    " * eta = 0.01, theta = [[11.70760718], [12.0794235 ]]\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P4Xl2Rs80kKC"
   },
   "source": [
    "### 1. Îç∞Ïù¥ÌÑ∞ Ï§ÄÎπÑ"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mBMxZ12I0kKC",
    "outputId": "e00de87c-7d87-4471-9fc4-3e577ab9a74f"
   },
   "source": [
    "np.random.seed(42)\n",
    "ùëã = 5 * np.random.rand(100,1)\n",
    "y = 20 + 9*ùëã +np.random.rand(100,1)*3\n",
    "X_b = np.c_[np.ones((100, 1)), X]  # add x0 = 1 to each instance\n",
    "theta = np.random.randn(2, 1)\n",
    "plot_generated_data(X, y)"
   ],
   "execution_count": 483,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAERCAYAAAB8eMxzAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAa1klEQVR4nO3df5Bdd3nf8fezu46c2lapZcP0l1DNEJyABydsAjs0ZBO7ZXDbhEGdVsSpFAh2BmQ3ykAn0Qw2WwtGBTKgjk1CNQVq1W3jehAkQDJhTK2OQxfDqomZqhFuTWsBNRNZJcY/0Mr2Pv3j3Nu9urq/dvecvT/O+zWzs77n3N373bH9ud/7nO95vpGZSJLqY2rYA5AkbS6DX5JqxuCXpJox+CWpZgx+SaqZmWEPoJ8rrrgid+zYMexhSNJYOX78+BOZeWWncyMf/Dt27GBpaWnYw5CksRIRj3U7Z6lHkmrG4JekmjH4JalmDH5JqhmDX5JqxuCXpJox+CVpiBYX4eDB4vtmGfl1/JI0qQ4fhltugRdegC1b4Etfgrm54tziIhw7BvPzq8fKYvBL0hAsLsLevfD888Xj5eUi6OfminPXXQfnzsEP/dD5bwhlsNQjSUNw7BisrKw+np4uZvfNc+fOFZ8Ezp0rHpfJ4JekIZifL8o7U1MwMwN33bU6q5+fL2b609PF9+YbQlks9UjSEMzNFSWcTnX8XufKEKO+5+7s7GzapE2S1iYijmfmbKdzlnokqWYMfknaBMNYr9+NNX5JqljVyzPXyhm/JFWs1/JM79yVpAnUXJ7ZnPE3l2cO65OAM35JqtjcHBw6VIT8oUOr4V71jVrdOOOXpIotLsK+fUW4P/ggXHNNEf7dPglUzeCXpIp1mtnPzVV/o1Y3Br8kVazXzL75BrCZDH5Jqkhra+VhzOy7MfglqQKdVuzs3z/sURVc1SNJFRjWip1BGPySVIL2G7Gqbq28EZZ6JGkdWuv30PlGrFGq67cy+CWpj/b9b9vr93v2dF+uOUqB32TwS1IXi4tw5Ah88pNFqDdn8+31exjOjVjrZfBLqrX22Xzr8euug7NnoblfVXM2374uf/fu4msUyzqdGPySaqtXk7TmrL4Z+hGrs/lu9ftRD/wmg19SbXVrpQDnz+pnZuBtbytm9a0hPy5B387gl1Rb/VopjOqqnI2qJPgjYhfwPmA78F3glzPzwYi4DvhY4/hDjeOPVTEGSfXWrXbfql+4j/OsvpfSgz8i/g7wQeAfA18F/mrj+BXAUeAdwOeAA8C9wOvKHoOkelvLBieTGu69VHHn7j8H7sjMr2TmSmZ+JzO/A7wFOJGZ92XmWWABeHVEXF3BGCTV2KDtEkZpA/TNVOqMPyKmgVng9yPifwIXA58F/hnwSuDh5nMz85mIeLRx/GTb77kZuBlg+/btZQ5RUg0MssHJqG2AvpnKnvG/BLgI+IfATwPXAj8OvBe4FHiy7flPApe1/5LMPJyZs5k5e+WVV5Y8REmTrlm7P3Cge6CPchO1qpUd/D9ofL8zMx/PzCeAjwA3AE8DW9uevxV4quQxSKq5QS7sjnITtaqVWurJzO9FxLeB7HD6BLCn+SAiLgFe1jguSaUYtIQzycs1+6ni4u6ngFsj4sUR8VeAfcDngc8Ar4qInRFxMXA78PXMPNn9V0nS2qylhDM3V2yOUqfQh2qC/wDwNeAR4M+APwE+kJmngZ3AB4DvAa8FdlXw+pJqrM4lnEFFZqeqzOiYnZ3NpaWlYQ9D0hgZpMY/6SLieGbOdjpnywZJE6eON2WthVsvSlLNGPySVDOWeiSNpfY9b+te018Lg1/S2Gldqz89XWyS8vzz9Wu9sF6WeiQN1XoapbWu1X/uufq2XlgvZ/yShqb9Lttbb4U//VPYuRNuvrnzsszFRTh1qpjpw4Uzftft92fwSxqa1pn78jJ86EPF8S9+ER59FO688/zWC7D6RjEzAzfdVGyH2Pxd1vgHY/BLGprW9snt95IePdq5hNM8BrB9+/htdD4KrPFLGprW9snvec/5597ylgtbL9iOoRzO+CUNVftdtkePFqH/wQ/Cm998YQmnrh01y2SvHkkjoXmhd3m5mNHfdVdxgVfr06tXj6UeSZVY6zLNY8eK0F9ZKZZo7t1bv71wN4ulHkmlW89+tvPzxUx/ZaV4vLJSvBlYzimfM35JpVvPfrZzc0V5Z2YGpqZgyxYv3lbFGb+kDWu/0ap1meZaVt/cfDNcc40Xb6tm8EvakG5lnfWuvrGXfvUMfkkb0qms0wxvA3w0WeOXtCHeVDV+nPFLWrdmbf/QIThz5sKyjnvfjiaDX9K69FuyuZ4lndoclnokrUu/JZtHjsDZs/bJH0UGv6R16VXbX1yET31qtePm9LS1/1FiqUfSuvRasnnsWLExChSbpLz97ZZ5RonBL2ndui3ZbL+Bq7lZikaDwS+pdBu5gUvVM/glrVuv5ZrewDW6DH5JPXULd5drji+DX1JXvcK9W6sGjT6Xc0rqqtdafVs1jC9n/JK66tVe2Qu448vgl9RVv3D3Au54Mvgl9WS4Tx5r/JJUMwa/VAOLi3DwYPFdKr3UExHHgNcBjU4dfCczX9E4dx3wMWA78BDwy5n5WNljkLTK9fZqV9WM/5bMvLTx1Qz9K4CjwG3A5cAScG9Fry9NtPYZfK8Zfb/2yf1+XpNnMy/uvgU4kZn3AUTEAvBERFydmSc3cRzSWGufwR86BPv2dZ/R91qS2en3+Ylg8lU14z8YEU9ExJcjYr5x7JXAw80nZOYzwKON4+eJiJsjYikilk6fPl3REKXx1D6D//Sne8/om0syDxzoHOqDfCLQZKlixv8bwH8HzgG7gM9FxLXApUB7ij8JXNb+CzLzMHAYYHZ2NisYozS22mfwO3fCgw92n9FD7yWZ/T4RaPKUHvyZ+VDLw7sj4q3ADcDTwNa2p28Fnip7DNIk63RT1TXXrP8OWu/ArZ/IrHZCHRF/CPwhcBbYk5mvbxy/hOITwE/0qvHPzs7m0tJSpWOUpEkTEcczc7bTuVJr/BHxooh4Y0RcHBEzEXEj8Abgj4DPAK+KiJ0RcTFwO/B1L+xKG+OKHK1V2aWei4D3A1cDLwAngTdn5jcAImIncBdwD8U6/l0lv75UC80e+du2dV7R02uDFKnU4M/M08BP9jh/P8WbgqR1al1+GQErK8VX64ocl2eqF1s2SGOmdfnlykrRD7+1J77LM9WP3TmlMdNcfrm8DFNT8Ou/Di960fllHZdnqhdn/NKYmZsr7tadni5m/HfeeX7o97thS3LGL42ItVyQPXPmwtp+68/YQ1+9DDTjj4iPR0RGxF/rcO4VEXEuIv5l+cOTJk+n5ZfNC7a33VZ877c00/1utRGDzvgXgV8Ffgr4bNu5jwLfBxZKG5U0obo1ROt0QbbXjN27bbURgwb/Vxrfzwv+iPh7wJuAvZn5vXKHJk2ebgE/aL+c9nKQga/1GCj4M/MbEfF/KYIfgIi4CPgI8N+Af1XN8KTJ0i3gB5nB2z5ZZVnLxd2vAK+PiMiiwc+vAT8CXJ+ZL1QyOmnC9Ar4fjP4tZaDpG7WGvw3AK9ozP5vAz6bmV+qZGTShFpvicb2ySrLWoK/uc7gpygar20B3l36iKQx1lqDh3IvvnpBV2VZS/A/BKwAvwL8beDDmfnNSkYljaHWGvz0dNFH5/nny63He0FXZRj4zt3MfIpiZ603AH8OfKCqQUnjqLUG/9xz9svR6Fpry4avNr7vb7wRSGpovalqerroozM1ZT1eo2fg4G8s35wHloC7qxqQNK6aNfibbiqCP7MI/kOHLizPuHmKhmktNf73AH8LuDGr3q9RGlPNu3Cff77ooxNR9NVp5Xp8DVvPGX9EXB4Rb42Ig8AB4COZ+ZVePyPVXb8+OvbL17D1m/G/Efj3FBdzPwr8ZuUjksZcs+Rz5Ejn867H17DFqFdtZmdnc2lpadjDkNakXznHPXFVtYg4npmznc7Zj1+qQL/2Cq7H1zC5A5dUAfvla5Q545fWoV+pxvYKGmUGv7RGi4vwsz+7Wr9/4IHu4W/gaxRZ6lHtbPTmqSNHYHm5uEFrebn76h1pVDnjV61485TkjF81U8bNU7t3F28aEcX33bvLHqVULWf8qo3FRTh1CmYa/9X3W23T7QJusy2DF241rgx+TbzFxaIO/8lPFjP96emikdru3d1Du19JyAu3GmcGvyZaM8DPni0uxjZt3+7+tqova/yaaM0Ab4Z+sy7f74Yqb8DSJHPGr4nW2hBtZgbe9rbOJZ72er43YGmSGfyaaIMEeLd6vnV8TSqDXxOvX4Bbz1fdWONX7VnPV91UEvwR8fKIOBsR97Qcuy4iTkbEsxHxQES8tIrXltaqWQ46cMA7eVUPVZV6PgZ8rfkgIq4AjgLvAD5HsY3jvcDrKnp9aU2s56tOSp/xR8Qu4C+AL7UcfgtwIjPvy8yzwALw6oi4uuzXlyT1VmrwR8RW4A7g3W2nXgk83HyQmc8AjzaOd/o9N0fEUkQsnT59uswhSlLtlT3jPwB8IjO/1Xb8UuDJtmNPApd1+iWZeTgzZzNz9sorryx5iJJUb6XV+CPiWuB64Mc7nH4a2Np2bCvwVFmvL0kaTJkXd+eBHcCpiIBilj8dET8GfBzY03xiRFwCvAw4UeLrawL029JQ0saVGfyHgd9tefweijeCdzYefzgidgJfAG4Hvp6ZJ0t8fY25QTdJ8c1B2pjSgj8znwWebT6OiKeBs5l5uvF4J3AXcA/wELCrrNfWZBjkDlp30JI2rrKWDZm50Pb4fsDlm+qqtaFatztoba8gbZy9ejQyBmmoNsibg6TeDH5tmkFq8/3uoLVdsrRxBr82xSC1+UEv2tpeQdoYg1+bol9t3ou20uaxLbM2Rb/Wx53eGCRVwxm/Ns2exi18nbY+bL9ou20bHDy4+gZhTV8qj8Gvyh0+DHv3wsoKbNlSBH+71ou227bBvn2r++RmFp8ELAFJ5bDUo0otLsItt8DzzxfBv7zcvYwzNwf798OZM+eXfZ57zhKQVCaDX6VZXCzKM4uLq8eOHStCu2lqqv/a+/brARdd5LaIUpks9agU3VblzM8X5Z3l5SK877qrf6mmfa0+WOOXymTwqxStq3KWl2Fhofha7w1X7Wv1DXypPAa/StEszywvF7X8+++HBx9cnfkb3NLosMavUszNwaFDcNVVEFGEvxdjpdHkjF+lWFwslmAuLxfLL6emvBgrjSpn/CpFs8a/slLM+K+6qvgEYIlHGj0Gv9atdflms8Y/NVXM+L/5zeITQOvSTkmjweDXujSXb952W/Edigu5119fhL81fml0Gfzqq9uNWcvLq8s3m902FxaKdfvecCWNLi/uqqduN2Zt21bM6qH4vm1b8c9ulCKNPoNfPXXro3/mzGpJZ2qqeNzkun1ptFnqUU/d+ug3WzFMTxffLelI48MZv3rqVrqxpCONr8jMYY+hp9nZ2VxaWhr2MCRprETE8cyc7XTOUo/WpNMKH0njxVKPLrC42LmE44bo0mQw+HWeXuHebYWPpPFiqUfn6RTuTd1W+EgaL874J1S3ck0/zXBvzvhbw92VPNJkMPgn0EZq8f3C3ZuzpPFn8E+Q5iz/1KmN1eINd2myGfwTonWWPzNT1OHBWrykCxn8E2BxseiK2dzvFuCmm2D7dmvxki5k8I+h1gu3UMz0m6Hf3PJw924DX1JnBv+Yab9wu2fP6paHU1PFRigLC4a+pO5KX8cfEfdExOMR8f2IeCQi3tFy7rqIOBkRz0bEAxHx0rJff9K1r7OH1bX1W7YY+pL6q+IGroPAjszcCvw88P6IeE1EXAEcBW4DLgeWgHsreP2JNj9fXLyNKL7v3l0svzxwwBYKkgZTeqknM0+0Pmx8vQx4DXAiM+8DiIgF4ImIuDozT5Y9jknWbKja/O7yS0lrUUnLhoj47Yh4FjgJPA78AfBK4OHmczLzGeDRxvH2n785IpYiYun06dNVDHGk9eqAeexYUebJLL67mbmktark4m5mvisibgXmgHlgGbgUaE/xJ4HLOvz8YeAwFP34qxjjqOp3122vlgqSNIjKVvVk5gvAH0fELwHvBJ4GtrY9bSvwVFVjGEf9OmA2WyocOTKsEUoad5uxnHOGosZ/AtjTPBgRl7Qcr632ZmqDzujvvrt4zt13F28EYPM0SYMpNfgj4sXAzwGfB34AXA+8FfhF4L8AH46IncAXgNuBr9f5wm63sk6/DpjtnwqOHFl9I3CDFEn9lH1xNynKOt8Gvgf8FrAvM38vM08DO4EPNM69FthV8uuPlW697+fmYP/+7uHd3hcfuvfQl6R2pc74G+H+Mz3O3w9cXeZrjotO/fEHLeu0/2z7pwI4f8bvBV9JvdiyYRN0K+kMUtbp9bOtz3eDFEmDMvg3Qa+VOp1uvmqd4Q+6z603cUkalMG/Cday9r59hn/okOv2JZXL4N8EvUo67fX79hn+mTOWcSSVy+CvSKcLsp1KOu31+06fDizjSCqTwV+BQTc771S/37/fGb6kahn8FRj0gmy32r8zfElVMvhL1CzvbNs22AXZQZZzSlLZDP6SdFqNc+ZM/0B3di9psxn8G9Sc5Z86deFqnP37hz06SbqQwb8BrbP8mZmidw643l7SaDP4++jUY6ep9SIuwE03wfbtndfqN/vn795taUfScBn8Pax1N6xOob64WDzv3Lni8ac+BQ88YPhLGp5K9tydFN3aJjc1V+UcONB7rf5zz60+tm2ypGFzxt/DID12+q3KmZ+Hiy5anfFb/5c0bAZ/D2Wss2/237HGL2lURGYOeww9zc7O5tLS0rCH8f/1utgrSaMiIo5n5mync87412DQHjySNMq8uLsG/S72StI4qF3wLy7CwYPF97U+t32Tcy/SShpHtSr19CvVtNbvofNzDx2CT38adu60zCNpPNUq+Hu1S25/U9izZ/W5y8uwsFCE/b59xfEHH4RrrjH8JY2fWpV62ks127atlnLa3xSgeM7UFKyswP33w969xZuANX5J46xWM/7Wdfnbtq3O3jttar57d/G1sFCE/spK8TumpyHCGr+k8VWr4IfVO20PHrywjXKn+v3CQlHWWWuffUkaVbUL/qb2dgytnwBa6/fukiVp0tQ2+NsDvdeFX3fJkjRJahv8cGGgD7JPriSNu4kN/k49dXr12bGkI6kuJjL4O92oBf377FjSkVQHExn83XrqdKvhS1KdTGTwd9tAxRq+JE1o8Her11vDlyQ3YpGkidRrI5Za9eqRJJUc/BGxJSI+ERGPRcRTEfEnEfGmlvPXRcTJiHg2Ih6IiJeW+fqSpP7KnvHPAN8Cfgb4y8BtwH+MiB0RcQVwtHHscmAJuLfk15ck9VHqxd3MfAZYaDn0+Yj4X8BrgG3Aicy8DyAiFoAnIuLqzDxZ5jgkSd1VWuOPiJcAPwKcAF4JPNw813iTeLRxvP3nbo6IpYhYOn36dJVDlKTaqSz4I+Ii4N8Bdzdm9JcCT7Y97UngsvafzczDmTmbmbNXXnllVUOUpFqqZB1/REwB/xY4B9zSOPw0sLXtqVuBp3r9ruPHjz8REY+tYxhXAE+s4+fGnX93vfh318ta/u6ui2dKD/6ICOATwEuAGzLzucapE8CeluddAryscbyrzFzXlD8ilrqtYZ1k/t314t9dL2X93VWUen4H+FHgH2TmD1qOfwZ4VUTsjIiLgduBr3thV5I2V9nr+F8K/CpwLfDdiHi68XVjZp4GdgIfAL4HvBbYVebrS5L6K3s552NA9Dh/P3B1ma/Zw+FNep1R499dL/7d9VLK3z3yvXokSeWyV48k1YzBL0k1Y/BLUs1MXPBHxOUR8ZmIeKbRJfQXhz2mqkXELY0WF8sR8W+GPZ7N0q8b7CSLiHsi4vGI+H5EPBIR7xj2mDZLRLw8Is5GxD3DHstmiYhjjb+5uVLyGxv5fRMX/MDHKO4YfglwI/A7EXFBP6AJ83+A9wOfHPZANlnXbrDDHNQmOQjsyMytwM8D74+I1wx5TJvlY8DXhj2IIbglMy9tfL1iI79oooK/cTfwTuC2zHw6M/8Y+H3gnwx3ZNXKzKOZ+VngzLDHspky85nMXMjM/52ZK5n5eaDZDXaiZeaJzFxuPmx8vWyIQ9oUEbEL+AvgS0MeylibqOCn6AT6QmY+0nLsYTp0ANXkaesGO/Ei4rcj4lngJPA48AdDHlKlImIrcAfw7mGPZUgORsQTEfHliJjfyC+atOAfuAOoJkuHbrATLzPfRfHf9k9TbHK03Psnxt4B4BOZ+a1hD2QIfgO4CvjrFDdxfS4i1v0Jb9KCf10dQDXeunSDrYXMfKFR0vwbwDuHPZ6qRMS1wPXAR4c8lKHIzIcy86nMXM7Mu4EvAzes9/dV0pZ5iB4BZiLi5Zn5PxrHXk1NPvrXUY9usHUzw2TX+OeBHcCp4l85lwLTEfFjmfkTQxzXsCQ92uP0M1Ez/sauXkeBOyLikoh4PfALFLPBiRURM42Op9MU/zNcHBGT9qbeTbdusBMrIl4cEbsi4tKImI6INwJvBf7TsMdWocMUb2zXNr4+DnwBeOPwhrQ5IuJFEfHG5v/XEXEj8Abgj9b7Oycq+BveBfww8OfAfwDemZmTPuN/L/AD4DeBX2r883uHOqJN0Ksb7HBHVrmkKOt8m6LT7W8B+zLz94Y6qgpl5rOZ+d3mF0VZ92yj6++ku4hiufZpik1YbgXenJnrXstvkzZJqplJnPFLknow+CWpZgx+SaoZg1+Sasbgl6SaMfglqWYMfkmqGYNfkmrG4JekmjH4pR4i4ocj4tsRcSoitrSd+9cR8UJjcxBpbBj8Ug+Nxm/vA/4mRR8oACLiIPArwK2Z+btDGp60LvbqkfqIiGmKndxeTLEZxjso+sK/LzPvGObYpPUw+KUBRMTfBz5HsdfrzwF3ZeY/He6opPWx1CMNoLGR+38FrgPuBX6t/TkRsTcivhoRZyPi2CYPURpYXTbrkDYkIv4RRd9/gKey80flx4F/AfwkMLdJQ5PWzOCX+oiIv0uxi9tngOeAt0fERzPzz1qfl5lHG8/fvvmjlAZnqUfqISJeS7Gd55eBGyl2NlsBDg5zXNJGGPxSFxHxoxT7uj5CsdXdcmY+SrG5+y809nSWxo7BL3XQKNd8EXgSeFNmfr/l9B0U+xp/aBhjkzbKGr/UQWaeorhpq9O5x4G/tLkjkspj8EsliYgZiv+nZoCpiLgYWMnMc8MdmXQ+g18qz3sp2js0/QD4z8D8UEYjdeGdu5JUM17claSaMfglqWYMfkmqGYNfkmrG4JekmjH4JalmDH5Jqpn/BxQpeBw1hsFyAAAAAElFTkSuQmCC\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-akhUpoK0kKE"
   },
   "source": [
    "### 1.1 eta = 0.1ÏùºÎïå, theta = [[21.45978618], [ 9.00541536]] Ïù¥Îãà Ï†ïÎãµÏùÑ ÎèÑÏ∂úÌï† Ïàò ÏûàÍ≤å ÏΩîÎìúÎ•º ÏûëÏÑ±ÌïòÏãúÏò§."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "k0_i5wjb0kKE"
   },
   "source": [
    "eta = 0.1 # learning rate\n",
    "n_iterations = 100\n",
    "m = 86.533\n",
    "\n",
    "theta = np.random.randn(2, 1) # random initialization\n",
    "\n",
    "for iteration in range(n_iterations):\n",
    "    gradients = 2/m * X_b.T.dot(X_b.dot(theta) - y)\n",
    "    theta = theta - eta * gradients\n",
    "\n",
    "print(theta)"
   ],
   "execution_count": 484,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[21.4597236 ]\n",
      " [ 8.84314567]]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PGaS4A4J0kKE"
   },
   "source": [
    "### 1.2  eta = 0.01ÏùºÎïå, theta = [[11.70760718], [12.0794235 ]] Ïù¥Îãà Ï†ïÎãµÏùÑ ÎèÑÏ∂úÌï† Ïàò ÏûàÍ≤å ÏΩîÎìúÎ•º ÏûëÏÑ±ÌïòÏãúÏò§."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "REzN1GUc0kKF"
   },
   "source": [
    "eta = 0.01 # learning rate\n",
    "n_iterations = 100\n",
    "m = 100\n",
    "\n",
    "theta = np.random.randn(2, 1) # random initialization\n",
    "\n",
    "for iteration in range(n_iterations):\n",
    "    gradients = 2/m * X_b.T.dot(X_b.dot(theta) - y)\n",
    "    theta = theta - eta * gradients\n",
    "\n",
    "print(theta)"
   ],
   "execution_count": 485,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12.34409869]\n",
      " [11.87879346]]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZNq2vjB80kKF"
   },
   "source": [
    "## Question 2\n",
    "Build a mini-batch gradient descent.\n",
    "* nuber or iterations = 50\n",
    "* initial learning rate eta = 0.1 \n",
    "* the learning rate reduce by half after every 10 epochs trained.\n",
    "* Find theta.\n",
    "\n",
    "**< Tip >**\n",
    "\n",
    "creat a learning_schedule function takes initial eta and current epochs as inputs.\n",
    " * n = epochs//10\n",
    " * eta = initial eta * 2 ^ (-n)\n",
    " \n",
    "Ï†ïÎãµ : theta = [[21.45560249], [ 9.00669781]] Ïù¥Îãà Ï†ïÎãµÏùÑ ÎèÑÏ∂úÌï† Ïàò ÏûàÍ≤å ÏΩîÎìúÎ•º ÏûëÏÑ±ÌïòÏãúÏò§."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "petZopN00kKF"
   },
   "source": [
    "n_iterations = 50\n",
    "minibatch_size = 20\n",
    "\n",
    "theta = np.random.randn(2, 1) # random initialization\n",
    "\n",
    "t0,t1 = 200, 1000\n",
    "\n",
    "def learning_schedule(t):\n",
    "    return t0 / (t + t1)\n",
    "\n",
    "t = 0\n",
    "for epoch in range(n_iterations):\n",
    "    shuffled_indices = np.random.permutation(m)\n",
    "    X_b_shuffled = X_b[shuffled_indices]\n",
    "    y_shuffled = y[shuffled_indices]\n",
    "    for i in range(0, m, minibatch_size):\n",
    "        t += 1\n",
    "        xi = X_b_shuffled[i:i+minibatch_size]\n",
    "        yi = y_shuffled[i:i+minibatch_size]\n",
    "        gradients = 2/minibatch_size * xi.T.dot(xi.dot(theta) - yi)\n",
    "        theta = theta - eta * gradients\n",
    "\n",
    "print(theta)"
   ],
   "execution_count": 486,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16.56261222]\n",
      " [10.57190381]]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jwkgB-D-0kKG"
   },
   "source": [
    "## Question 3\n",
    "Build a Logistic regression model to reconize Iris-Versicolor with following requirements\n",
    "* Use 2 features >> sepal width, petal length\n",
    "* Randomly split Iris data into training - test sets with ratio 8:2 using train_test_split with random_state = 10.\n",
    "* Report the accuracies of model on training and test set.\n",
    "\n",
    "**< Tip >**\n",
    "\n",
    "model.score(data,target) ÏùÑ ÏÇ¨Ïö©Ìï¥ Ï†ïÌôïÎèÑÎ•º Íµ¨ÌïòÏãúÏò§.\n",
    "\n",
    "Ï†ïÎãµ : ÌïôÏäµ Ï†ïÌôïÎèÑÎäî 0.7167Ïù¥Í≥† Test Ï†ïÌôïÎèÑÎäî 0.7333ÏûÖÎãàÎã§."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DeT2vDSt0kKG"
   },
   "source": [
    "### 1. Îç∞Ïù¥ÌÑ∞ Î°úÎìú\n",
    "### 1.1) Iris Îç∞Ïù¥ÌÑ∞ Î°úÎìú"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "AxN5fpm60kKG"
   },
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()"
   ],
   "execution_count": 487,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_tBd5l6V0kKG"
   },
   "source": [
    "### 1.2) xÏôÄ yÍ∞í ÏÑ§Ï†ï."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HudwZp5b0kKH"
   },
   "source": [
    "X = iris[\"data\"][:, 3:] # extract data contain only petal width\n",
    "y = (iris[\"target\"] == 2).astype(np.int) # target = 1 if Iris-Virginica, else 0"
   ],
   "execution_count": 488,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-488-fa96070d18da>:2: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y = (iris[\"target\"] == 2).astype(np.int) # target = 1 if Iris-Virginica, else 0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f4YksscY0kKH"
   },
   "source": [
    "### 1.3) TrainÍ≥º Test Îç∞Ïù¥ÌÑ∞ Íµ¨Î≥Ñ\n",
    "* train_test_split(feature, target, test_size, random_state)Î•º ÏÇ¨Ïö©Ìï¥ÏÑú ÌïôÏäµÍ≥º ÌÖåÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞ÏÖãÏùÑ Íµ¨Î≥ÑÌï©ÎãàÎã§."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uwzjpnqs0kKH"
   },
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)"
   ],
   "execution_count": 489,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tIHWEQO40kKH"
   },
   "source": [
    "### 2. Î™®Îç∏ ÎπåÎìú\n",
    "### 2.1) LogisticRegressionÎ™®Îç∏ ÎπåÎìú"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5sp9hZit0kKH"
   },
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression()"
   ],
   "execution_count": 490,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cDeR-0PQ0kKH"
   },
   "source": [
    "### 2.2) LogisticRegression ÌõàÎ†®"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "AYmOrq340kKI"
   },
   "source": [
    "log_reg.fit(X, y)"
   ],
   "execution_count": 491,
   "outputs": [
    {
     "data": {
      "text/plain": "LogisticRegression()"
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S2dQ9uyc0kKI"
   },
   "source": [
    "### 3. ÏÑ±Îä• ÌèâÍ∞Ä\n",
    "### 3.1) ÌïôÏäµ Îç∞Ïù¥ÌÑ∞Î°ú Ïä§ÏΩîÏñ¥ ÌèâÍ∞Ä(Ï†ïÌôïÎèÑ)\n",
    "* ÌïôÏäµ Ï†ïÌôïÎèÑÎäî 0.7167Ïù¥Îã§."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UQLgRgrT0kKI"
   },
   "source": [
    "train_accuracy_score = log_reg.score(X_train, y_train)\n",
    "print(train_accuracy_score)"
   ],
   "execution_count": 492,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jyCdt0-F0kKI"
   },
   "source": [
    "### 3.2) ÌÖåÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞Î°ú Ïä§ÏΩîÏñ¥ ÌèâÍ∞Ä(Ï†ïÌôïÎèÑ)\n",
    "* Test Ï†ïÌôïÎèÑÎäî 0.7333Ïù¥Îã§."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nY2i0ktl0kKI"
   },
   "source": [
    "test_accuracy_score = log_reg.score(X_test, y_test)\n",
    "print(test_accuracy_score)"
   ],
   "execution_count": 493,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ]
  }
 ]
}