{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Lec6_student_file_v1.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.13"}},"cells":[{"cell_type":"code","metadata":{"id":"hdKwI9c4eu_v"},"source":["import tensorflow as tf\n","from tensorflow import keras\n","import numpy as np\n","import os\n","# to make this notebook's output stable across runs\n","np.random.seed(42)\n","%load_ext tensorboard\n","# To plot pretty figures\n","%matplotlib inline\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","mpl.rc('axes', labelsize=14)\n","mpl.rc('xtick', labelsize=12)\n","mpl.rc('ytick', labelsize=12)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wtQwswhHeu_z"},"source":["# Lab 1: Nonsaturating Activation Functions"]},{"cell_type":"code","metadata":{"id":"1DtHthCjeu_0"},"source":["(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n","X_train_full = X_train_full / 255.0\n","X_test = X_test / 255.0\n","X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n","y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Du6DswTkeu_0"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gE_fInaVeu_1"},"source":["# Lab 3: Faster Optimizers"]},{"cell_type":"code","metadata":{"id":"rGfpCkKveu_1"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S9r-mjGMeu_1"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mWlSRPhBeu_2"},"source":["## Try some optimizers"]},{"cell_type":"code","metadata":{"id":"1N30Jj1Weu_2"},"source":["pixel_means = X_train.mean(axis=0, keepdims=True)\n","pixel_stds = X_train.std(axis=0, keepdims=True)\n","X_train_scaled = (X_train - pixel_means) / pixel_stds\n","X_valid_scaled = (X_valid - pixel_means) / pixel_stds\n","X_test_scaled = (X_test - pixel_means) / pixel_stds"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9Sba3zG_eu_3"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fOgGar1jeu_3"},"source":["# Lab 4: Learning Rate Scheduling"]},{"cell_type":"markdown","metadata":{"id":"fPmEfqhmeu_3"},"source":["## Power Scheduling"]},{"cell_type":"code","metadata":{"id":"f0e-wfcheu_3"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"khpuTMomeu_4"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GzYfzFI4eu_4"},"source":["learning_rate = 0.01\n","decay = 1e-4\n","batch_size = 32\n","n_steps_per_epoch = len(X_train) // batch_size\n","epochs = np.arange(n_epochs)\n","lrs = learning_rate / (1 + decay * epochs * n_steps_per_epoch)\n","\n","plt.plot(epochs, lrs,  \"o-\")\n","plt.axis([0, n_epochs - 1, 0, 0.01])\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Learning Rate\")\n","plt.title(\"Power Scheduling\", fontsize=14)\n","plt.grid(True)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hwU7zUp3eu_4"},"source":["## Exponential Scheduling"]},{"cell_type":"code","metadata":{"id":"pRwxu8f7eu_5"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rhg1qeLReu_5"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PtsAtDd2eu_5"},"source":["plt.plot(history.epoch, history.history[\"lr\"], \"o-\")\n","plt.axis([0, n_epochs - 1, 0, 0.011])\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Learning Rate\")\n","plt.title(\"Exponential Scheduling\", fontsize=14)\n","plt.grid(True)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YUsVaAs8eu_5"},"source":["## Piecewise Constant Scheduling"]},{"cell_type":"code","metadata":{"id":"vFIf85-7eu_5"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lGLh1rsYeu_5"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UFjfkoLbeu_5"},"source":["plt.plot(history.epoch, [piecewise_constant_fn(epoch) for epoch in history.epoch], \"o-\")\n","plt.axis([0, n_epochs - 1, 0, 0.011])\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Learning Rate\")\n","plt.title(\"Piecewise Constant Scheduling\", fontsize=14)\n","plt.grid(True)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zc7Dt09Jeu_6"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3wgn-tGneu_6"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6ZR3M0UPeu_6"},"source":["# 연습문제"]},{"cell_type":"markdown","metadata":{"id":"AvYn3VCgeu_6"},"source":["## Question 1\n","Train a deep model on MNIST fashion dataset with different learning rate: lr = 1e-2, 1e-4, and 1e-6.\n","\n","1) **Model architecture (모델 구조)**\n"," * Input layer (Flatten)\n"," * Dense layer (size = 300), relu, he_normal\n"," * Dense layer (size = 100), relu, he_normal\n"," * Output layer\n","\n","2) Use Adam optimization and train the network on the MNIST fashion dataset for 20 epochs.\n","\n","3) Tensorboard setup code is provided.\n","\n","4) Compare the learning curves in tensorboard and give your comments.\n"]},{"cell_type":"markdown","metadata":{"id":"FbHuIFVBoETg"},"source":["### 1. 데이터 로드\n","### 1.1 패션 MNIST 데이터 로드"]},{"cell_type":"code","metadata":{"id":"2YuLYZGOoETg"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4g1dFsesoETh"},"source":["### 1.2 기본적인 전처리하시오.\n","* 이미지 값을 0-255 사이 값을 0-1 사이 값으로 바꾸어 정규화시킵니다.\n","* 학습 데이터를 인덱스 50000 기준으로 train과 vaild로 분할합니다.\n","* 학습 데이터셋의 평균과 표준편차를 구해 표준화(StandardScale)를 시킵니다."]},{"cell_type":"code","metadata":{"id":"mexXEIyYoETh"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DsVJa92qoETh"},"source":["### 2. 모델 빌드\n","* 단, np.random.seed(42)와 tf.random_set_seed(42)를 반드시 고정시킵니다.\n","\n","#### **... 부분에 들어갈 코드를 작성하시오.**"]},{"cell_type":"code","metadata":{"id":"IABNFQb3eu_6"},"source":["np.random.seed(42)\n","tf.random.set_seed(42)\n","\n","n_epochs = 20\n","\n","for lr in [...]:\n","    tf.keras.backend.clear_session()\n","    \n","    run_logdir = os.path.join(os.curdir, \"my_logs\", \"Q1_lr_\"+ str(lr))\n","    tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n","\n","    optimizer = keras.optimizers.Adam(lr=lr)\n","    \n","    #complete your model\n","\n","    model = ...\n","\n","    model.compile(...) \n","\n","    model.fit(X_train_scaled, y_train, epochs=n_epochs,\n","              validation_data=(X_valid_scaled, y_valid),\n","              callbacks=tensorboard_cb)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9kMTBzx_oETh"},"source":["### 3. 텐서보드 실행하시오."]},{"cell_type":"code","metadata":{"id":"YTKGp1rEeu_7"},"source":["%tensorboard --logdir=./my_logs --port=6006"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"13KJsrDreu_7"},"source":["## Question 2\n","Train a deep model on MNIST fashion dataset with different learning rate: lr = 1e-2, 1e-4, and 1e-6.\n","\n","1) **Model architecture (모델 구조)**\n"," * Input layer\n"," * Dense layer (size = 300), relu, he_normal\n"," * Batch normalize\n"," * Dense layer (size = 100), relu, he_normal\n"," * Output layer\n","\n","\n","2) Use Adam optimization and train the network on the MNIST fashion dataset for 20 epochs.\n","\n","3) Tensorboard setup code is provided.\n","\n","4) Compare the learning curves in tensorboard and give your comments."]},{"cell_type":"markdown","metadata":{"id":"OUVJ_j8SoETh"},"source":["### 1. ... 부분 코드 작성하시오."]},{"cell_type":"code","metadata":{"id":"5q0fWhKneu_7"},"source":["np.random.seed(42)\n","tf.random.set_seed(42)\n","\n","n_epochs = 20\n","\n","for lr in [...]:\n","    tf.keras.backend.clear_session()\n","    \n","    run_logdir = os.path.join(os.curdir, \"my_logs\", \"Q2_lr_\"+ str(lr))\n","    tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n","\n","    optimizer = keras.optimizers.Adam(lr=lr)\n","    \n","    #complete your model\n","\n","    model = ...\n","\n","    model.compile(...) \n","\n","    model.fit(X_train_scaled, y_train, epochs=n_epochs,\n","              validation_data=(X_valid_scaled, y_valid),\n","              callbacks=tensorboard_cb)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jK87Qi5_oETi"},"source":["### 2. 텐서보드 실행하시오."]},{"cell_type":"code","metadata":{"id":"RFkPhiraeu_7"},"source":["%tensorboard --logdir=./my_logs --port=6006"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XhB0K-kreu_7"},"source":["## Question 3\n","Train a deep model on MNIST fashion dataset with different dropout rate: 0.1, 0.5, and 0.9\n","\n","\n","1) **Model architecture (모델 구조)**\n"," * Input layer\n"," * Dense layer (size = 300), relu, he_normal\n"," * Batch normalize\n"," * Dense layer (size = 100), relu, he_normal\n"," * Dropout \n"," * Output layer\n","\n","\n","2) Use Adam optimization (learning rate = 0.01) and train the network on the MNIST fashion dataset for 20 epochs.\n","\n","3) Tensorboard setup code is provided.\n","\n","4) Compare the learning curves in tensorboard and give your comments."]},{"cell_type":"markdown","metadata":{"id":"QzmTTSp6oETi"},"source":["### 1. ... 부분 코드 작성하시오."]},{"cell_type":"code","metadata":{"id":"yQ1PYf51eu_7"},"source":["np.random.seed(42)\n","tf.random.set_seed(42)\n","\n","n_epochs = 20\n","\n","for dropout_rate in [...]:\n","    tf.keras.backend.clear_session()\n","    \n","    run_logdir = os.path.join(os.curdir, \"my_logs\", \"Q3_dropout_rate_\"+ str(dropout_rate))\n","    tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n","\n","    optimizer = ...\n","    \n","    #complete your model\n","\n","    model = ...\n","\n","    model.compile(...) \n","\n","    model.fit(X_train_scaled, y_train, epochs=n_epochs,\n","              validation_data=(X_valid_scaled, y_valid),\n","              callbacks=tensorboard_cb)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mcn7t93UoETi"},"source":["### 2. 텐서보드 실행하시오."]},{"cell_type":"code","metadata":{"id":"eeM8wa7Qeu_8"},"source":["%tensorboard --logdir=./my_logs --port=6006"],"execution_count":null,"outputs":[]}]}